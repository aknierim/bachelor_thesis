\chapter{Data processing with \ctapipe{}}
\label{ch:data-processing}

The analysis in this work was done with the open-access low-level data processing software for \cta{},
\ctapipe{} \cite{ctapipe}. The version used is the development version \texttt{0.15.1.dev166+gf26107f},
henceforth shortened to version \texttt{0.15.1}. The goal of \ctapipe{} is to provide a complete analysis
framework ranging from data calibration and image extraction to the reconstruction of events and the
analysis of their properties.

\section{Data Levels in \ctapipe{}}
\label{sec:data-levels}

There are several data levels in \ctapipe{}, spanning from the raw data \rzero{} to the reconstructed events
\dlt{}, with the raw data levels being denoted by a \textbf{R} and the calibrated data levels by a \textbf{D}.
\autoref{fig:ctapipe} shows a simplified overview of the data levels and the analysis steps.
The raw data level \rzero{} is the data that comes directly from the photodetectors. The time-resolved
signal of the data is calibrated from \rzero{} to \rone{}. Then the data volume gets reduced
(\rone{} \rightarrow \dlz{}) by a selection of waveforms. The \dlz{} data level is the first level being
stored and also the first level to be processed from the simulation datasets used in this work.
From \dlz{} to \dloa{}, the images of the data are extracted from the time pulses, which are then
cleaned by a cleaning algorithm, allowing for parametrization of the events (\dloa{} \rightarrow \dlob{}).
The parametrized events can then be reconstructed (\dlob{} \rightarrow \dlt{}) and stored on the \dlt{} data level.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{graphics/ctapipe.png}
    \caption{Data levels in \ctapipe{}. Raw data levels are denoted by a \textbf{R} and calibrated
    data levels by a \textbf{D}. The raw data first gets calibrated (\rzero{} \rightarrow \rone{})
    and then reduced in volume by selecting waveforms (\rone{} \rightarrow \dlz{}). From there the
    images are extracted (\dlz{} \rightarrow \dloa{}) and cleaned with a cleaning algorithm. This
    allows for parametrization of the events (\dloa{} \rightarrow \dlob{}). The parametrized events
    can then be reconstructed (\dlob{} \rightarrow \dlt{}) \cite{noethe_thesis, hackfeld}. \todo[inline]{citation}}
    \label{fig:ctapipe}
\end{figure}

\section{This work's data processing pipeline}
\label{sec:pipeline}

In this work, the data processing pipeline is as follows: First, several simulation data runs are
selected and processed with \ctapipe{}. Then, the datasets are merged and serve as a basis for a re-run
of the combined dataset with various parameter combinations described in \autoref{ch:finding-hyperparams}.
Each resulting dataset can then be processed on an array- or telescope data level, resulting in
\dloa{} image plots, angular resolution and effective area or efficiency as well as metrics for the
performance. An \todo{wording}in-detail description of how this helps to compare the performance of the different
cleaning algorithms can be found in \autoref{sec:hyperparameters}. \autoref{fig:data-processing} shows
a schematic overview of the data processing pipeline of this work.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{graphics/data_pipeline.pdf}
    \caption{Schematic overview of the data pipeline used for this work. Single runs of the simulation
    data are processed with \ctapipe\texttt{-process} and then merged via \ctapipe\texttt{-merge}.
    The merged data is then processed on the array- or telescope data level resulting in scores for metrics
    as well as \texttt{dl1 images} and plots for the angular resolution and the effective area.}
    \label{fig:data-processing}
\end{figure}

\begin{minipage}{\textwidth}
  \begin{mdframed}[backgroundcolor=white!20!black,leftmargin=0cm,rightmargin=0cm, skipabove=0pt, innerleftmargin=0,innerrightmargin=0,]
  \begin{pythonlst}
    def metrics(events, output_file_metrics, unique_file_id):
        """Calculates the metrics for the given telescope type.

        Parameters:
        -----------
        events: astropy.table.Table
            The events table. Must contain the following columns:
            - true_image: The true image of the event.
            - image: The event image containing background noise.
        output_file_metrics: pathlib.Path
            The path to the output file for the metrics.
        unique_file_id: int
            The unique file id for the input file.
        """

        # initialize the metrics calculator
        metrics_calc = TprFprCalculator(
            true_image=events["true_image"],
            image=events["image"],
            clean_mask=events["image_mask"]
        )

        # calculate the metrics
        metrics_data = metrics_calc.tpr_fpr()

        # write metrics data to DataFrame and then to a file
        metrics = pd.DataFrame(data=metrics_data)
        metrics.insert(loc=0, column='unique_file_id', value=unique_file_id)
        metrics.to_csv(
            output_file_metrics,
            index=False,
            mode='a',
            header=not output_file_metrics.exists()
        )
  \end{pythonlst}
  \end{mdframed}
\end{minipage}

